Reasearch Questions API (Improvement) - Ongoing
- Outline critical campaign question which will be covered by the API
	- General Trends
		- What is most talked about (regardless of area or topic)
			- Topic Modeller to extract topics
				- GENSIM
			- Use extracted topics to label data
			- Count the most occurent topics
		- What is the sentiment towards what is being discussed?
			- Filter the dataset by occurent topics as well as sentiment.
	- Politicians' Reputation (Reasearch Questions about the Candidates/Politicians)
		- Who is most talked about?
			- Count using already created list of politicians
		- What questions are being asked about this candidate?
			- Try Topic Modeller to extract topics from filtered tweets
			- Try Getting most common words from tokenized words after removing stop words.
			- Try getting most common  sentence structure components (NounPhrase, Object etc) from tweets.
		- Popularity or notoreity of the most talked about.
			- Sentiment after filtering by most occuring candidate.
		- Most popular, and most notorious candidates/politician.
			- Candidate with highest positive sentiment
			- Candidate with highest negative sentiment
		- How much is a certain candidate being talked about?
			- Count after filtering by any candidate.
		- What is being said about each candidate?
			- Try Topic Modeller to extract topics from filtered tweets
			- Try Getting most common words from tokenized words after removing stop words.
			- Try getting most common  sentence structure components (NounPhrase, Object etc) from tweets.
		- What is the general sentiment of what is being said about ?
			- Label each row after filtering by candidate with extracted topics and check sentiment.
	- Citizens' Sentiment (Research Question about the Citizens)
		- What is the general sentiment of the citizens?
			-Count most occurent sentiment
	- Discourse Areas (Research Question about the Citizens Complaints)
		- What are the various areas of complaints as regards to governance?
			Manually labelled categories for tweets.
			- Infrastructure
			- Education
			- Health
			- Security
			- Policies
			- Economic Indicators (e.g. inflation, exchange rate, trade balance)
			- Unrelated
		- What is most discussed(election and governance related)?
			- Count Tweets after filtering by area of discourse.
		- Specific elements of discussion for the different areas.
			- Filter by already labelled discourse areas
			- Tokenize the Dataset
			- Remove stop words
			- Use Frequency Distribution to get most common words
			- Build Word cloud using most common words.
		- What are the levels of sentiment towards the various area of complaints?
			- Count Tweets after filtering by both sentiment and area of discourse.
			
	- These research questions can be narrowed down from national level, to state level, as well as local government level.
	- These same architecture can be scaled and adjusted to any nation and economy.
- Answer these question using analytical methods and ML algorithms and make these answers available at endpoints for future analysts.

- Tables will be created to hold this information (precalculated in an automated script), to save response time for the API

- Step by step Approach
	- One research area section is selected and build upon for integration and deployment. - Done
	- Elaborate explanations are outlined on how to execute the same methods on the different regions, in future phases. - Done
	- Categories for our manual labelling - Done
		- Sentiment
			- Positive
			- Indifferent
			- Negative
		- Discourse Areas
			- Infrastructure
			- Education
			- Health
			- Security
			- Policies
			- Economic Indicators (e.g. inflation, exchange rate, trade balance)
			- Unrelated

	- After the new set of data from the database has been cleaned (Abiye), and appended to the old data. This cleaned column of the dataset will remove also the tweeter handles in order not to bias the predictive model. -Done
	- Predict positive and negative sentiment.
	- Predict dicourse area.
	- These predicted labels will be attached to the new extracted dataset.
		- General Trends
			- Use GENSIM for Topic Modelling to extract most popular trends (like first 5), by region (Nigeria first, then the states filtering by location)
			- Create a General Trends table with columns (Region, Topics Ranking (1,2,3,...,10), Most contributing word, second contributing word, third contributing word, fourth contributing word, fifth contributing word).
				- The rows of the Region columns will be Nigeria, and the 36 states.
				- The rows of the topic ranking columns will be the order of popularity of each topic/trend.
				- The rows of the most contributing words (etc.) will be the  contributing words extracted by the topic modeller for the entire dataset, and for the filtered dataset by each state using the GENSIM topic modeler.
				- Each region (e.g Nigeria, Lagos, Rivers etc.) will have 5 allocated rows, for the top 5 trends, and their contributing words.
				
				- For sentmient analysis of each state, the cleaned dataset will be filtered by the location using and the sentiment count is taken.

		- Politician's Reputation
			- Use GENSIM to extract the most popular trends, after filtering py politicians name using the filter function for public office holders (Abiye)
			- Create 37 table (Nigeria and the 36 states)
			- Each table will have the columns (Public Office Holder, Most popular trend, second trend, third trend, positive sentiment count, negative sentiment count).
				- The rows of the first column will be the list of public office holders.
				- The rows of the topic ranking columns will be the order of popularity of each topic/trend.
				- The rows of the most contributing words (etc.) will be the  contributing words extracted by the topic modeller for the entire dataset, and for the filtered dataset by each state using the GENSIM topic modeler.
				- Each politician will have 5 allocated rows, for the top 5 trends, and their contributing words.

				- For sentmient analysis of each politician, the cleaned dataset will be filtered by the said politician using the clean function and the sentiment count is taken.
			- Questions like 'most popular or notorious public office holder' will be answered by checking the public office holder with the highest count for positive or negative sentiment.

		- Citizen's Sentiment/Complaint -(Due to heavily unbalanced extracted data, this section will be suspended till improvement on the type of extracted data is made.)
			- Use GENSIM for Topic Modelling to extract most popular trends (like first 5), by region (Nigeria first, then the states filtering by location), after having filtered by each of the categories in our discourse area label.
			- Create a table for each discourse area with columns (Region, Most popular trend, second trend, third trend, positive sentiment count, negative sentiment count).
				- The rows of the Region columns will be Nigeria, and the 36 states.
				- The rows of the trends columns will be the topics extracted for the entire dataset, and for the filtered dataset by each discourse area using the GENSIM topic modeler.
				- The rows of sentiment columns will be the count of each of the sentiments, after applying the respective filters.

		Main Next Focus
		- Loading the GENSIM corpus and the saved models from github.
			-Load Model from Github: https://stackoverflow.com/questions/64097109/load-a-tensorflow-h5-model-hosted-online
			-Load Corpus from Kaggle: https://stackoverflow.com/questions/57984502/how-to-access-use-googles-pre-trained-word2vec-model-without-manually-downloadi
		-https://stackoverflow.com/questions/65298241/what-does-this-tensorflow-message-mean-any-side-effect-was-the-installation-su
		-https://stackoverflow.com/questions/69769139/relative-file-path-is-not-recognized-by-python-in-vscode
		-https://www.geeksforgeeks.org/python-schedule-library/

		First Push
		- Pull original dataset
		- Clean, Transform and Predict Labels with Ensemble Model
		- Push new cleaned dataset to the database (using df.to_sql())
		- Pull new cleaned dataset from database
		- Model topics for General Trend and Politician's Reputation
		- Push topics dataset to database.

		Subsequent Push
		- Pull original dataset
		- Filter by date and retain only most recent date
		- Clean, Transform and Predict Labels with Ensemble Model
		- Push new predicted rows to the already existing cleaned dataset
		- Delete data older than 7 days using the date column.
		- Pull entire cleaned dataset from database
		- Model topics for General Trend and Politician's Reputation
		- Push (add) new trends to the already existing topics dataset in the database
		- Delete any topics older than seven days using the date column. 

Dashboard Creation
- PowerBi connection to the hosted database to visualize the information answered in the research questions section, as well the general data and display this visuals on a dashboard which will be published for non-technical persons.


Election Database (Improvement) -Done
- Email notification after every scheduled database update
	- Containing
		- Execution logs
		- Quantity added, Quantity removed
		- Prevent data corruption from bots, by removing duplicate tweets.


Election Campaign TPL (Improvement)
- This section will reflect whichever changes made in the API.


UI/UX - Ongoing
- Detailed Conceptual of the UI/UX of the entire platform, which obviously include the "citizens' voice".

Important Observation for Future System Improvement.
Note-Labelling: If this project is scaled up, then deciding the labels and labelling the data will have to be done by professional psychologists.
	- This is because our interpretation of sentiment as non-professionals in the field of psychology introduces a lot of bias in the interpretation of the sentiment of a certain text, also there is little experience as to how to effectively categorize the various sentiment.
	- Also a solution needs to be proposed on how to effectively split tweets with different sentiment for different subjects in the same tweet.
	- Should a text be labeled as positive or neative independent of the context or not?

Note-Topic Modelling: Latent Dirichlet Allocation
	- All handles will be removed before the topic modelling is done.

Note-Sentiment:
	- A good language analysis has to account to context in sentences.
	- There are two major kinds of context hidden in sentences.
			- Context in the sequence of words (Relational Context): This accounts for grammar (language structure)
				- This can be accounted for by combining any sentence or word encoder with RNN (SimpleRNN or LSTM), which takes note of word sequences.
			- Context in the meaning of words (Internal Context): This accounts for meaning of words, therefore is the same sentence is consturcted using synonyms, the meaning can be understood as the same.
				- This can be accounted for by a combination of different methods.
				- Using GENSIM word2vec encoder to encode each word in the sentence.
				- Using PCA to summarize each word to it's principal components.
				- Or using simple average on each word to keep uniform vector output at all times.
				- Replacing each word with their principal values or simple average (which then accounts for meaning and similarity)
	- Combining these two methods of context retention, we can account for both Relational Context and Internal Context.
		- GENSIM Word2Vec and SimpleRNN are to be experimented with in this project.
		- To combine Word2Vec with LSTM (Embedding Layer), I might need to customize my own vocab dictionary.
		- Further study required.
			- Checkout BERT sentence encoder
				- This should account synonymous words/sentences.
				- Synonymous sentences is independent of the sequence of words in the sentence.
			- This can then account for both the internal and relational context in texts.
				- If combined with a pretty big enough MLP, can give you both of both worlds
				- Your model could general and specialize at the same time.
			- This is already accounted for by the combination of RNNs and GENSIM Word2Vec, hence it is simply a different way of achieving same results.
				- Is it faster or simpler to train and build, this is dependent on result of further experiments.
			- Both approaches could account for extreme cases of language use like 'Double/Triple Entendere', and still generalize to big data.